{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from compiler.ast import flatten\n",
    "from random import Random\n",
    "from pandas import DataFrame\n",
    "from numpy import log\n",
    "from numpy import mat\n",
    "from numpy import ones\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomforest(object):\n",
    "    n_estimators=0 # 树的数量\n",
    "    max_features=0 #每棵树的选用数据集的最大特征数\n",
    "    min_samples_split=0 #每棵树最小分割数\n",
    "    min_gain=0 #每一颗树到min_gain之后就停止\n",
    "    max_depth=0 #每一颗树的最大层数\n",
    "    trees=[] #森林\n",
    "    trees_feature=[] #用来记录每一个树用了哪些特征\n",
    "    \n",
    "    def __init__(self,n_estimators=100,min_samples_split=3, min_gain=0,\n",
    "                 max_depth=None,max_features=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_gain = min_gain\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features \n",
    "        \n",
    "#         #建立森林(bulid forest)\n",
    "#         for _ in range(self.n_estimators):\n",
    "#             tree =DecisionTreeClassifier(min_samples_split=self.min_samples_split, min_impurity_split = self.min_gain,\n",
    "#                                       max_depth=self.max_depth)\n",
    "#             self.trees.append(tree)\n",
    "            #self.trees_feature.append(0)\n",
    "        \n",
    "    def get_bootstrap_data(self,X,Y):\n",
    "        # 用bookstarp的方法获得n_estimators组随机的数据\n",
    "        \n",
    "        m=X.shape[0]\n",
    "        Y=Y.reshape(m,1)\n",
    "        \n",
    "        #合并X和Y\n",
    "        X_Y=np.hstack((X,Y))\n",
    "        np.random.shuffle(X_Y) #X_Y随机化\n",
    "        \n",
    "        result_sets=[]\n",
    "        for _ in range(self.n_estimators):\n",
    "            now=np.random.choice(m,m,replace=True) #有放回,随机序列顺序\n",
    "            bootstrap_X_Y = X_Y[now,:]\n",
    "            bootstrap_X =  bootstrap_X_Y[:,:-1]\n",
    "            bootstrap_Y =  bootstrap_X_Y[:,-1:]\n",
    "            result_sets.append([bootstrap_X,bootstrap_Y])\n",
    "            \n",
    "        return result_sets\n",
    "    \n",
    "    def fit(self,X_train,Y_train):\n",
    "        # 每一颗树都通过get_bookstrap_data获得随机的数据集\n",
    "        \n",
    "        sub_sets=self.get_bootstrap_data(X_train,Y_train)\n",
    "        n_features=X_train.shape[1]\n",
    "        \n",
    "        if self.max_features == None:\n",
    "            self.max_features = int(np.sqrt(n_features))\n",
    "\n",
    "        for i in range (self.n_estimators):\n",
    "            # 现在为每一颗树选择随机的特征\n",
    "            tree =DecisionTreeClassifier(min_samples_split=self.min_samples_split,min_impurity_decrease = self.min_gain,\n",
    "                                      max_depth=self.max_depth)\n",
    "            \n",
    "            sub_X,sub_Y=sub_sets[i]\n",
    "            features=np.random.choice(n_features,self.max_features,replace=True)\n",
    "            sub_X=sub_X[:,features]\n",
    "            #print(\"X\",sub_X)\n",
    "            #print(\"X\",sub_Y)\n",
    "            tree.fit(sub_X,sub_Y)\n",
    "            self.trees.append(tree)\n",
    "            self.trees_feature.append(features)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        y_preds=[]\n",
    "        for i in range(self.n_estimators):\n",
    "            features=self.trees_feature[i]\n",
    "            sub_X=X[:,features]\n",
    "            y_pre=self.trees[i].predict(sub_X)\n",
    "            y_preds.append(y_pre)\n",
    "        \n",
    "        y_preds=np.array(y_preds).T\n",
    "        #print(y_preds)\n",
    "        y_pred=[]\n",
    "        \n",
    "        for y_p in y_preds:\n",
    "            y_pred.append(np.bincount(y_p.astype('int')).argmax()) #np.bincount()可以统计每个索引出现的次数,np.argmax()可以返回数组中最大值的索引\n",
    "        #print(mat(y_pred).shape)\n",
    "        y_pred=np.mean(y_preds,axis=1)\n",
    "        #print(\"2\",mat(y_pred).shape)\n",
    "        return y_pred\n",
    "        \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    adult_header=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\n",
    "              \"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\n",
    "              \"capital-loss\",\"hours-per-week\",\"native-country\",\"label\"]\n",
    "    adult_data=pd.read_csv(\"./adult.data\",index_col=False,names=adult_header)\n",
    "    adult_test=pd.read_csv(\"./adult2.test\",index_col=False,names=adult_header)\n",
    "    #adult_data.shape\n",
    "    #adult2.test的数据是adult的数据删去label的最后一个字符\".\"得到的;\n",
    "    adult_data[adult_data==\" ?\"]=np.nan\n",
    "    adult_test[adult_test==\" ?\"]=np.nan\n",
    "    #print(adult_data[\"age\"])\n",
    "    adult_data.dropna(axis=0,how='any',inplace=True)\n",
    "    adult_test.dropna(axis=0,how='any',inplace=True)\n",
    "    discre_name=[\"workclass\",\"education\",\"marital-status\",\n",
    "             \"occupation\",\"relationship\",\"race\",\n",
    "             \"sex\",\"native-country\",\"label\"]\n",
    "    for name in discre_name:\n",
    "        key=np.unique(adult_data[name])\n",
    "        #print(key)\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le.fit(key)\n",
    "        adult_test[name]=le.transform(adult_test[name])\n",
    "        adult_data[name]=le.transform(adult_data[name])\n",
    "    \n",
    "    data = np.vstack((adult_data, adult_test))\n",
    "    X = data[:, 0:-1]\n",
    "    Y = data[:, -1]\n",
    "    return X, Y\n",
    "#print(adult_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_header=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\n",
    "#               \"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\n",
    "#               \"capital-loss\",\"hours-per-week\",\"native-country\",\"label\"]\n",
    "# adult_data=pd.read_csv(\"./adult.data\",index_col=False,names=adult_header)\n",
    "# adult_test=pd.read_csv(\"./adult2.test\",index_col=False,names=adult_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_data[adult_data==\" ?\"]=np.nan\n",
    "# adult_test[adult_test==\" ?\"]=np.nan\n",
    "# #print(adult_data[\"age\"])\n",
    "# adult_data.dropna(axis=0,how='any',inplace=True)\n",
    "# adult_test.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discre_name=[\"workclass\",\"education\",\"marital-status\",\n",
    "#              \"occupation\",\"relationship\",\"race\",\n",
    "#              \"sex\",\"native-country\",\"label\"]\n",
    "# for name in discre_name:\n",
    "#     key=np.unique(adult_data[name])\n",
    "#     #print(key)\n",
    "#     le=preprocessing.LabelEncoder()\n",
    "#     le.fit(key)\n",
    "#     adult_test[name]=le.transform(adult_test[name])\n",
    "#     adult_data[name]=le.transform(adult_data[name])\n",
    "# #print(adult_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larryytr/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomforest: T=100: auc=0.843301 \n",
      "Randomforest: T=200: auc=0.876355 \n",
      "Randomforest: T=300: auc=0.880239 \n",
      "Randomforest: T=400: auc=0.887233 \n",
      "Randomforest: T=500: auc=0.883040 \n",
      "Randomforest: T=600: auc=0.876355 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b0883d80fdc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 X, Y, test_size=.20, random_state=i*serand)\n\u001b[1;32m     29\u001b[0m         \u001b[0mRandom_classfier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandomforest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#参数记得填\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mRandom_classfier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mY_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandom_classfier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#y_pred=mat(Adaboost_classfier.predict(X_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-91bdb4b23389>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m#print(\"X\",sub_X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m#print(\"X\",sub_Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # X_data=adult_data.values[0:150,0:14]\n",
    "# # #print(X_data[:,0:14])\n",
    "# # Y_data=adult_data.values[0:150,14]\n",
    "# # #print(Y_data)\n",
    "# # X_test=adult_test.values[0:150,0:14]\n",
    "# # #print(X_test[:,0:14])\n",
    "# # Y_test=adult_test.values[0:150,14]\n",
    "# # print(Y_test)\n",
    "# # #记得删除\n",
    "# X_data=np.array(adult_data.values[:,0:14])\n",
    "# #print(X_data[:,0:14])0\n",
    "# Y_data=np.array(adult_data.values[:,14])\n",
    "# #print(Y_data)\n",
    "# X_test=np.array(adult_test.values[:,0:14])\n",
    "# #print(X_test[:,0:14])\n",
    "# Y_test=np.array(adult_test.values[:,14])\n",
    "# X=np.vstack((X_data,X_test))\n",
    "# Y=np.hstack((Y_data,Y_test))\n",
    "X,Y=get_data()\n",
    "test_num=5\n",
    "\n",
    "for t in range(1,10):\n",
    "    serand=t\n",
    "    mean_auc=0.0\n",
    "    mean_score=0.0\n",
    "    for i in range(test_num):\n",
    "        X_data,X_test,Y_data,Y_test=train_test_split(\n",
    "                X, Y, test_size=.20, random_state=i*serand)\n",
    "        Random_classfier=randomforest(t*100) #参数记得填\n",
    "        Random_classfier.fit(X_data,Y_data)\n",
    "        Y_pred=mat(Random_classfier.predict(X_test))\n",
    "        #y_pred=mat(Adaboost_classfier.predict(X_test))\n",
    "        Y_pred.astype(np.int)\n",
    "        Y_pred=np.array(np.ravel(Y_pred))\n",
    "        Y_true=np.array(Y_test)\n",
    "        precision, recall, thresholds = precision_recall_curve(Y_true,Y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        mean_auc+=pr_auc\n",
    "#         score=accuracy_score(Y_test, np.array(Y_pred))\n",
    "#         mean_score+=score\n",
    "        \n",
    "    print(\"Randomforest: T=%d: auc=%f \"%(t*100,(mean_auc/test_num)))\n",
    "kf = KFold(n_splits=5,random_state=0)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(train_index,test_index)\n",
    "    X_data=X[train_index]\n",
    "    X_test=X[test_index]\n",
    "    Y_data=Y[train_index]\n",
    "    Y_test=Y[test_index]\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "# a1 = np.random.choice(9,1,replace=False, p=None)\n",
    "# print(a1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Y=np.random.rand(5,1)\n",
    "# print(Y)\n",
    "# X=np.random.rand(5,9)\n",
    "# m=X.shape[0]\n",
    "# print(X)\n",
    "# X_Y = np.hstack((X,Y))\n",
    "# np.random.shuffle(X_Y)\n",
    "\n",
    "# data_sets = []\n",
    "# for _ in range(1):\n",
    "#     idm = np.random.choice(m,m,replace=True)\n",
    "#     bootstrap_X_Y = X_Y[idm,:]\n",
    "#     bootstrap_X =  bootstrap_X_Y[:,:-1]\n",
    "#     bootstrap_Y =  bootstrap_X_Y[:,-1:]\n",
    "#     data_sets.append([bootstrap_X,bootstrap_Y])\n",
    "\n",
    "# print(data_sets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_classfier=randomforest() #参数记得填\n",
    "# X_data.replace(np.nan, 0, inplace=True)\n",
    "Random_classfier.fit(X_data,Y_data)\n",
    "y_pred=Random_classfier.predict(X_test)\n",
    "print(y_pred)\n",
    "y_true=np.array(Y_test)\n",
    "precision, recall, thresholds = precision_recall_curve( y_true,y_pred)\n",
    "score=accuracy_score(y_true, y_pred)\n",
    "print(score)\n",
    "pr_auc = auc(recall, precision)\n",
    "test_auc =metrics.roc_auc_score(y_true, y_pred)#验证集上的auc值\n",
    "pl.plot(recall, precision)\n",
    "print(\"auc\",roc_auc_score(y_true, y_pred))\n",
    "print(\"auc\",test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
