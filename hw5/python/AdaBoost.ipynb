{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from compiler.ast import flatten\n",
    "from random import Random\n",
    "from pandas import DataFrame\n",
    "from numpy import log\n",
    "from numpy import mat\n",
    "from numpy import ones\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adaboost (object):\n",
    "    T=500\n",
    "    m=0\n",
    "    weakClassArr=[]\n",
    "    weakalpha=[]\n",
    "    max_depth=0\n",
    "    min_samples_split=2\n",
    "    def __init__(self,T,min_samples_split=2):\n",
    "        self.T=T\n",
    "        self.mins_sample_split=min_samples_split\n",
    "        \n",
    "    def fit(self,X_train,Y_train):\n",
    "        self.max_depth=X_train.shape[1]\n",
    "        #self.m=X_train.shape[0]\n",
    "        #m=shape(X_train)[0]\n",
    "        m=X_data.shape[0]\n",
    "        D=ones((m))/m\n",
    "        epsilon = 0.001\n",
    "        errorThreshold = 0.00001\n",
    "        maybe=X_data.shape[1]\n",
    "        #print(\"sdsd\",D.shape)\n",
    "        #print(\"sdsd\",type(D))\n",
    "        #aggClassEst=mat(zeros((self.m,1)))\n",
    "        for i in range(self.T):\n",
    "            dt_stump=DecisionTreeClassifier(max_depth=maybe, \n",
    "                                            min_samples_split=self.min_samples_split)\n",
    "            dt_stump.fit(X_data,Y_data,sample_weight=np.array(D))\n",
    "            Y_pred=dt_stump.predict(X_data)\n",
    "            error=mat(ones(m))\n",
    "            error[mat(Y_pred)==mat(Y_data)]=0#error shape:(1,30621)\n",
    "            \n",
    "            error=D.T*error.T\n",
    "            if error > 0.5:\n",
    "                print(\"T = %d >0.5 break\" % i)\n",
    "                break\n",
    "            if error < errorThreshold:\n",
    "                print(\"T = %d <errorThreshold break\" % i)\n",
    "            \n",
    "            #print(error)\n",
    "            \n",
    "            alpha=float(0.5*log((1.0-error+epsilon)/(error+epsilon)))\n",
    "            self.weakalpha.append(alpha)\n",
    "            self.weakClassArr.append(dt_stump)\n",
    "            #print(alpha)\n",
    "#             expon=np.multiply(-1*alpha*mat(Y_data).T,mat(dt_stump.predict(X_data)))\n",
    "#             expon=-1*alpha*mat(Y_data).dot(mat(dt_stump.predict(X_data)).T)\n",
    "            #print(mat(Y_data).shape)\n",
    "            #print(mat(dt_stump.predict(X_data)).shape)\n",
    "#             D=np.multiply(D,np.exp(expon))\n",
    "#             D=mat(D).T*np.exp(expon)\n",
    "            D=D*\\\n",
    "                np.exp(-alpha*Y_pred*Y_data)\n",
    "            #print(D.shape)\n",
    "            D=np.ravel(D/D.sum())\n",
    "            #print(D)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        data=mat(X_test)\n",
    "        m=data.shape[0]\n",
    "        Y_pred=mat(np.zeros((m,1)))\n",
    "        \n",
    "        \n",
    "        for i in range (len(self.weakClassArr)):\n",
    "            weak_result=self.weakalpha[i]*mat(self.weakClassArr[i].predict(X_test))\n",
    "            \n",
    "            Y_pred+=weak_result.T\n",
    "            \n",
    "        #return np.ravel(np.sign(Y_pred))\n",
    "        return np.ravel(Y_pred) \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():  \n",
    "    #adult_data.shape\n",
    "    #adult2.test的数据是adult的数据删去label的最后一个字符\".\"得到的;\n",
    "    adult_header=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\n",
    "              \"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\n",
    "              \"capital-loss\",\"hours-per-week\",\"native-country\",\"label\"]\n",
    "    adult_data=pd.read_csv(\"./adult.data\",index_col=False,names=adult_header)\n",
    "    adult_test=pd.read_csv(\"./adult2.test\",index_col=False,names=adult_header)\n",
    "    #处理带有?的项目;\n",
    "    adult_data[adult_data==\" ?\"]=np.nan\n",
    "    adult_test[adult_test==\" ?\"]=np.nan\n",
    "    adult_data.dropna(axis=0,how='any',inplace=True)\n",
    "    adult_test.dropna(axis=0,how='any',inplace=True)\n",
    "    #对非数值的数据进行处理;\n",
    "    discre_name=[\"workclass\",\"education\",\"marital-status\",\n",
    "             \"occupation\",\"relationship\",\"race\",\n",
    "             \"sex\",\"native-country\",\"label\"]\n",
    "    for name in discre_name:\n",
    "        key=np.unique(adult_data[name])\n",
    "        #print(key)\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le.fit(key)\n",
    "        adult_test[name]=le.transform(adult_test[name])\n",
    "        adult_data[name]=le.transform(adult_data[name])\n",
    "    #合并测试,训练两个数据集(之后用5-折交叉验证找)\n",
    "    data = np.vstack((adult_data, adult_test))\n",
    "    X = data[:, 0:-1]\n",
    "    Y = data[:, -1]\n",
    "    return X, Y\n",
    "#print(adult_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_header=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\n",
    "#               \"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\n",
    "#               \"capital-loss\",\"hours-per-week\",\"native-country\",\"label\"]\n",
    "# adult_data=pd.read_csv(\"./adult.data\",index_col=False,names=adult_header)\n",
    "# adult_test=pd.read_csv(\"./adult2.test\",index_col=False,names=adult_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adult_data.shape\n",
    "#adult2.test的数据是adult的数据删去label的最后一个字符\".\"得到的;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_data[adult_data==\" ?\"]=np.nan\n",
    "# adult_test[adult_test==\" ?\"]=np.nan\n",
    "# #print(adult_data[\"age\"])\n",
    "# adult_data.dropna(axis=0,how='any',inplace=True)\n",
    "# adult_test.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(adult_data)\n",
    "#print(adult_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discre_name=[\"workclass\",\"education\",\"marital-status\",\n",
    "#              \"occupation\",\"relationship\",\"race\",\n",
    "#              \"sex\",\"native-country\",\"label\"]\n",
    "# for name in discre_name:\n",
    "#     key=np.unique(adult_data[name])\n",
    "#     #print(key)\n",
    "#     le=preprocessing.LabelEncoder()\n",
    "#     le.fit(key)\n",
    "#     adult_test[name]=le.transform(adult_test[name])\n",
    "#     adult_data[name]=le.transform(adult_data[name])\n",
    "# #print(adult_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我觉得可能还可以用one-hot的方法来处理类别;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larryytr/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost:T=5: auc=0.834737 score=0.817380\n",
      "Adaboost:T=10: auc=0.891577 score=0.760177\n",
      "Adaboost:T=15: auc=0.910316 score=0.708612\n",
      "Adaboost:T=20: auc=0.917338 score=0.670359\n",
      "Adaboost:T=25: auc=0.928907 score=0.645196\n",
      "Adaboost:T=30: auc=0.923350 score=0.618994\n",
      "Adaboost:T=35: auc=0.932279 score=0.604953\n",
      "Adaboost:T=40: auc=0.926520 score=0.587020\n",
      "Adaboost:T=45: auc=0.929397 score=0.578419\n"
     ]
    }
   ],
   "source": [
    "# X_data=np.array(adult_data.values[:,0:14])\n",
    "# #print(X_data[:,0:14])\n",
    "# Y_data=np.array(adult_data.values[:,14])\n",
    "# #print(Y_data)\n",
    "# X_test=np.array(adult_test.values[:,0:14])\n",
    "# #print(X_test[:,0:14])\n",
    "# Y_test=np.array(adult_test.values[:,14])\n",
    "# X=np.vstack((X_data,X_test))\n",
    "# Y=np.hstack((Y_data,Y_test))\n",
    "X,Y=get_data()\n",
    "test_num=5\n",
    "\n",
    "for t in range(1,10):\n",
    "    serand=t\n",
    "    mean_auc=0.0\n",
    "    mean_score=0.0\n",
    "    for i in range(test_num):\n",
    "        X_data,X_test,Y_data,Y_test=train_test_split(\n",
    "                X, Y, test_size=.20, random_state=i*serand)\n",
    "        Adaboost_classfier=adaboost(t*5,2)\n",
    "        Adaboost_classfier.fit(X_data,Y_data)\n",
    "        Y_pred=mat(Adaboost_classfier.predict(X_test))\n",
    "        #y_pred=mat(Adaboost_classfier.predict(X_test))\n",
    "        Y_pred.astype(np.int)\n",
    "        Y_pred=np.array(np.ravel(Y_pred))\n",
    "        Y_true=np.array(Y_test)\n",
    "        precision, recall, thresholds = precision_recall_curve(Y_true,Y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        mean_auc+=pr_auc\n",
    "        Y_pred=np.sign(Y_pred)\n",
    "        score=accuracy_score(Y_test, Y_pred)\n",
    "        mean_score+=score\n",
    "        \n",
    "    print(\"Adaboost:T=%d: auc=%f score=%f\"%(t*5,(mean_auc/test_num),mean_score/test_num))\n",
    "# kf = KFold(n_splits=5,random_state=0)\n",
    "\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     print(train_index,test_index)\n",
    "#     X_data=X[train_index]\n",
    "#     X_test=X[test_index]\n",
    "#     Y_data=Y[train_index]\n",
    "#     Y_test=Y[test_index]\n",
    "#     break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # m=X_data.shape[0]\n",
    "# D=ones((m))/m\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# # B=min_max_scaler.fit_transform(D)\n",
    "# print(D)\n",
    "# dt_stump=DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)\n",
    "# dt_stump.fit(X_data,Y_data,sample_weight=D.T)\n",
    "# error=mat(ones(m))\n",
    "# error[mat(dt_stump.predict(X_data))==mat(Y_data)]=0\n",
    "# print(error.T.shape)\n",
    "# error=D.T*error.T\n",
    "# B=ones((m,1))/m\n",
    "\n",
    "# alpha=float(0.5*log((1.0-error)/max(error,1e-16)))\n",
    "# weadsd=[]\n",
    "# weadsd.append(dt_stump)\n",
    "# expon=-1*alpha*mat(Y_data)*mat(dt_stump.predict(X_data)).T\n",
    "\n",
    "# print(\"exp\",np.exp(expon).shape)\n",
    "# # D=np.multiply(D.T,np.exp(expon))\n",
    "# print(mat(D))\n",
    "# D=mat(D).T*np.exp(expon)\n",
    "# print(D.shape)\n",
    "# D=D/D.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_of_classfier=1000\n",
    "# Adaboost_classfier=adaboost(num_of_classfier,2)\n",
    "# Adaboost_classfier.fit(X_data,Y_data)\n",
    "# y_pred=mat(Adaboost_classfier.predict(X_test))\n",
    "# y_pred.astype(np.int)\n",
    "# y_pred=np.array(np.ravel(y_pred))\n",
    "# print(np.ravel(y_pred))\n",
    "\n",
    "# y_true=np.array(Y_test)\n",
    "# #print(y_actual)\n",
    "# precision, recall, thresholds = precision_recall_curve( y_true,y_pred)\n",
    "# score=accuracy_score(y_true, y_pred)\n",
    "# print(score)\n",
    "# pr_auc = auc(recall, precision)\n",
    "# test_auc =metrics.roc_auc_score(y_true, y_pred)#验证集上的auc值\n",
    "# pl.plot(recall, precision)\n",
    "# print(\"classfier_num\",num_of_classfier)\n",
    "# print(\"auc\",roc_auc_score(y_true, y_pred))\n",
    "# print(\"auc\",test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
