{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from compiler.ast import flatten\n",
    "from random import Random\n",
    "from pandas import DataFrame\n",
    "from numpy import log\n",
    "from numpy import mat\n",
    "from numpy import ones\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adaboost (object):\n",
    "    T=500\n",
    "    m=0\n",
    "    weakClassArr=[]\n",
    "    weakalpha=[]\n",
    "    def __init__(self,T):\n",
    "        self.T=T        \n",
    "    def fit(self,X_train,Y_train):\n",
    "        \n",
    "        #self.m=X_train.shape[0]\n",
    "        #m=shape(X_train)[0]\n",
    "        m=X_data.shape[0]\n",
    "        D=ones((m))/m\n",
    "        print(\"sdsd\",D.shape)\n",
    "        print(\"sdsd\",type(D))\n",
    "        #aggClassEst=mat(zeros((self.m,1)))\n",
    "        for i in range(self.T):\n",
    "            dt_stump=DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)\n",
    "            dt_stump.fit(X_data,Y_data,sample_weight=D.T)\n",
    "            \n",
    "            error=mat(ones(m))\n",
    "            error[mat(dt_stump.predict(X_data))==mat(Y_data)]=0#error shape:(1,30621)\n",
    "            error=D.T*error.T\n",
    "            \n",
    "            alpha=float(0.5*log((1.0-error)/max(error,1e-16)))\n",
    "            self.weakalpha.append(alpha)\n",
    "            self.weakClassArr.append(dt_stump)\n",
    "            \n",
    "#             expon=np.multiply(-1*alpha*mat(Y_data).T,mat(dt_stump.predict(X_data)))\n",
    "            expon=-1*alpha*mat(Y_data)*mat(dt_stump.predict(X_data)).T\n",
    "           # print(D.shape)\n",
    "#             D=np.multiply(D,np.exp(expon))\n",
    "            D=mat(D).T*np.exp(expon)\n",
    "            #print(D.shape)\n",
    "            D=np.ravel(D/D.sum())\n",
    "            #print(D.shape)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        data=mat(X_test)\n",
    "        m=data.shape[0]\n",
    "        Sum=mat(np.zeros((m,1)))\n",
    "        \n",
    "        \n",
    "        for i in range (len(self.weakClassArr)):\n",
    "            weak_result=self.weakalpha[i]*mat(self.weakClassArr[i].predict(X_test))\n",
    "            #print(\"in\",self.weakClassArr[i].predict(X_test).shape)\n",
    "            #print(\"inasdas\",self.weakalpha[i].shape)\n",
    "            #print(\"inasdas\",weak_result.shape)\n",
    "            #print(\"sum\",Sum.shape)\n",
    "            Sum+=weak_result.T\n",
    "            \n",
    "        return np.ravel(np.sign(Sum))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_header=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\n",
    "              \"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\n",
    "              \"capital-loss\",\"hours-per-week\",\"native-country\",\"label\"]\n",
    "adult_data=pd.read_csv(\"./adult.data\",index_col=False,names=adult_header)\n",
    "adult_test=pd.read_csv(\"./adult2.test\",index_col=False,names=adult_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adult_data.shape\n",
    "#adult2.test的数据是adult的数据删去label的最后一个字符\".\"得到的;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larryytr/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "adult_data[adult_data==\" ?\"]=np.nan\n",
    "adult_test[adult_test==\" ?\"]=np.nan\n",
    "#print(adult_data[\"age\"])\n",
    "adult_data.dropna(axis=0,how='any',inplace=True)\n",
    "adult_test.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 15)\n"
     ]
    }
   ],
   "source": [
    "#print(adult_data)\n",
    "print(adult_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discre_name=[\"workclass\",\"education\",\"marital-status\",\n",
    "             \"occupation\",\"relationship\",\"race\",\n",
    "             \"sex\",\"native-country\",\"label\"]\n",
    "for name in discre_name:\n",
    "    key=np.unique(adult_data[name])\n",
    "    #print(key)\n",
    "    le=preprocessing.LabelEncoder()\n",
    "    le.fit(key)\n",
    "    adult_test[name]=le.transform(adult_test[name])\n",
    "    adult_data[name]=le.transform(adult_data[name])\n",
    "#print(adult_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我觉得可能还可以用one-hot的方法来处理类别;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-72762bd87da2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print(train_index,test_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mX_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mY_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "X_data=np.array(adult_data.values[0:150,0:14])\n",
    "#print(X_data[:,0:14])\n",
    "Y_data=np.array(adult_data.values[0:150,14])\n",
    "#print(Y_data)\n",
    "X_test=np.array(adult_test.values[0:150,0:14])\n",
    "#print(X_test[:,0:14])\n",
    "Y_test=np.array(adult_test.values[0:150,14])\n",
    "X=np.vstack((X_data,X_test))\n",
    "Y=np.hstack((Y_data,Y_test))\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(train_index,test_index)\n",
    "    X_data=X[train_index],X_test=X[test_index]\n",
    "    Y_data=Y[train_index],Y_test=Y[test_index]\n",
    "    break;\n",
    "print(kf.split(X))\n",
    "print(Y.shape)\n",
    "print(Y_data.shape)\n",
    "#记得删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # m=X_data.shape[0]\n",
    "# D=ones((m))/m\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# # B=min_max_scaler.fit_transform(D)\n",
    "# print(D)\n",
    "# dt_stump=DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)\n",
    "# dt_stump.fit(X_data,Y_data,sample_weight=D.T)\n",
    "# error=mat(ones(m))\n",
    "# error[mat(dt_stump.predict(X_data))==mat(Y_data)]=0\n",
    "# print(error.T.shape)\n",
    "# error=D.T*error.T\n",
    "# B=ones((m,1))/m\n",
    "\n",
    "# alpha=float(0.5*log((1.0-error)/max(error,1e-16)))\n",
    "# weadsd=[]\n",
    "# weadsd.append(dt_stump)\n",
    "# expon=-1*alpha*mat(Y_data)*mat(dt_stump.predict(X_data)).T\n",
    "\n",
    "# print(\"exp\",np.exp(expon).shape)\n",
    "# # D=np.multiply(D.T,np.exp(expon))\n",
    "# print(mat(D))\n",
    "# D=mat(D).T*np.exp(expon)\n",
    "# print(D.shape)\n",
    "# D=D/D.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaboost_classfier=adaboost(100)\n",
    "Adaboost_classfier.fit(X_data,Y_data)\n",
    "y_pred=mat(Adaboost_classfier.predict(X_test))\n",
    "y_pred.astype(np.int)\n",
    "y_pred=np.array(np.ravel(y_pred))\n",
    "print(np.ravel(y_pred))\n",
    "\n",
    "y_true=np.array(Y_test)\n",
    "#print(y_actual)\n",
    "precision, recall, thresholds = precision_recall_curve( y_true,y_pred)\n",
    "score=accuracy_score(y_true, y_pred)\n",
    "print(score)\n",
    "pr_auc = auc(recall, precision)\n",
    "test_auc =metrics.roc_auc_score(y_true, y_pred)#验证集上的auc值\n",
    "pl.plot(recall, precision)\n",
    "print(\"auc\",roc_auc_score(y_true, y_pred))\n",
    "print(\"auc\",test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
